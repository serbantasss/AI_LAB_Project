{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yooo\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1 id=\"AI-Lab---initial-guidelines-to-generate-your-reports\">AI Lab - initial guidelines to generate your reports<a class=\"anchor-link\" href=\"#AI-Lab---initial-guidelines-to-generate-your-reports\">¶</a></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>This is a small sample notebook for you with some information that you might use to generate you reports. It has some guidelines, some initial ideas, and some questions for you to think about and discuss. This is only an initial notebook, please organize as you like.</p>\n",
    "<p>I expect you to grow your notebooks into full project reports, with your work and results, the description of your steps, justification for your choices, and your ideas and considerations. Please use both text and visualisations to clarify results and concepts. Please try also to capture the discussion we had in class, and the discussion you had afterwards. The final reports should reflect the work of your group and your very own results, ideas and discussion.</p>\n",
    "<p>If you need domain specific knowlegde you can check again some of the handouts, and you can also explore further some of the links in the handouts, or you can ask. However, please try not to be too domain specific in your thinking and in your reports, try to to apply the theory you have learnt and use your observations and results to extract general underlying concepts.</p>\n",
    "<p>For the first AI Lab day we progress all together, and below I give you some more pointers for the first analysis steps. This is so you can familizarize with the data. After this, from day 2, you will progress more independently, and for days 3 and 4 you will divide into groups for the data challenge.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Introduction\">Introduction<a class=\"anchor-link\" href=\"#Introduction\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Please include a short introduction based on what we discussed in class:</p>\n",
    "<ul>\n",
    "<li>Background</li>\n",
    "<li>Overall Aim</li>\n",
    "<li>Specific Objectives</li>\n",
    "</ul>\n",
    "<p>[...]</p>\n",
    "<p>This should be based on what we discussed in class. Please ask any questions you have or clarifications, you can also consult the handouts. I would probably aim for no more than 200 words for this section.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Materials-and-Methods\">Materials and Methods<a class=\"anchor-link\" href=\"#Materials-and-Methods\">¶</a></h2><p>Please include:</p>\n",
    "<ul>\n",
    "<li>A short description of the data and how they were obtained.</li>\n",
    "<li>A short description of the methods you will use and why. </li>\n",
    "</ul>\n",
    "<p>[...]</p>\n",
    "<p>I would aim for no longer than 300 words, but you could also provide more details and justification of data and methods when you load them/use them in the following sections.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr/>\n",
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Python-libraries\">Python libraries<a class=\"anchor-link\" href=\"#Python-libraries\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Remember you can use command line mode if installations are needed\n",
    "#!pip install numpy==1.19.5\n",
    "#!pip install matplotlib\n",
    "#!pip install seaborn\n",
    "#!pip install pandas\n",
    "#[....] for you to add. Please include here for reference the libraries you will use. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt             #visualisation\n",
    "import seaborn as sns   #visualisation\n",
    "%matplotlib inline     \n",
    "sns.set(color_codes=True)\n",
    "#[....] for you to add\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2 id=\"Exploratory-data-analysis\">Exploratory data analysis<a class=\"anchor-link\" href=\"#Exploratory-data-analysis\">¶</a></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>First we load the data. There are four datasets. They correspond to four different experiments in two different cell lines, and using two different single cell RNA sequencing techniques. You might proceed one experiment at a time, or download the metadata for all experiments and discuss them together. Here I show the example for one of the datasets.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3 id=\"MCF7-SmartSeq-experiment\">MCF7 SmartSeq experiment<a class=\"anchor-link\" href=\"#MCF7-SmartSeq-experiment\">¶</a></h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>First we read in the metadata. There are 4 metadata files. One for each experiment. They are tab delimited file TSV.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Remember to change the path. This should point to where you have stored the metadata files. \n",
    "df_meta = pd.read_csv(\"SmartSeq/MCF7_SmartS_MetaData.tsv\",delimiter=\"\\t\",engine='python',index_col=0)\n",
    "print(\"Dataframe dimensions:\", np.shape(df_meta))\n",
    "print(\"First column: \", df_meta.iloc[ : , 0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_meta.head(5)   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>You comments</p>\n",
    "<ul>\n",
    "<li>what are the raws? </li>\n",
    "<li>what are the columns?</li>\n",
    "</ul>\n",
    "<p>[....]</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Next we download the actual sequencing data. In this case the datasets are space-delimited. The name of the file gives you information on cell line, the technology used and processing. The format is: CellLine_Technology_preprocessing_Data.txt</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>You can download all data files, and then discuss them together later, or proceed one data file at the time.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Remember to change the path. This should point to where you have stored the data files. \n",
    "df = pd.read_csv(\"SmartSeq/MCF7_SmartS_Unfiltered_Data.txt\",delimiter=\"\\ \",engine='python',index_col=0)\n",
    "print(\"Dataframe dimensions:\", np.shape(df))\n",
    "print(\"First column: \", df.iloc[ : , 0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>For each data file, describe its structure and content.</p>\n",
    "<ul>\n",
    "<li>File dimensions</li>\n",
    "<li>Raws/columns are</li>\n",
    "<li>This dataframe uses Symbols to identify genes (e.g. You can add the discussion we had in class on identifiers)\n",
    "[...]</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "list(df.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gene_symbls = df.index\n",
    "print(\"Dataframe indexes: \", gene_symbls)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong><em>Exploratory data analysis</em></strong> include a broad range of possible tasks:</p>\n",
    "<ul>\n",
    "<li>check how large are the files</li>\n",
    "<li>are the data types all numeric</li>\n",
    "<li>what can you observe by looking at the data (maybe use some plots to explain)</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.shape(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df.head(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df.dtypes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# you can go from data frame to matrix if you prefer\n",
    "X= df.to_numpy()\n",
    "X\n",
    "np.shape(X)\n",
    "#note this might need to be transposed later on in the analysis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The aim is to understand the data by summarizing their main characteristics (e.g. tables with statistics or visually). This step is the very first one when we analyse the data. It can be time consuming but it is very useful to understand the data, perform some quality control, and define the downstream analysis.</p>\n",
    "<p>Of note, there are ways of carrying out EDA and some steps that are domain specific, and even in the same domain sometimes there are different ways of carrying out EDA. It might depends on the specific technology or the specific question. However, most of the concepts are general and applicable to many contexts. The focus should be on the general context.</p>\n",
    "<p>You have an <strong>\"unfiltered\"</strong> data file. These are data are matrixes of counts, no filter was applied and no normalization was applied. It is a good idea to start to explore this first to understand the issues with the dataset and discuss them, and what are the general implications of the issues you encounter.</p>\n",
    "<p>You have also <strong>\"filtered\"</strong> data and <strong>\"normalized\"</strong> data. These have been pre-processed for you so eliminate some of the issues. You can use these to train your classifiers.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p><strong><em>Are there missing values in the data?</em></strong></p>\n",
    "<p>This is a recurring issues in many dataset, including in health. If there were missing data you could remove them, or try some missing data imputation.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#df = df.dropna()    # Dropping the missing values.\n",
    "#df.count()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#print(df.isnull().sum())   # After dropping the values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Other general questions you might like to ask yourself in EDA are:</p>\n",
    "<ul>\n",
    "<li><strong><em>are there some outliers in the features?</em></strong></li>\n",
    "<li><strong><em>are there outliers in the cases?</em></strong></li>\n",
    "<li><strong><em>are the data normalized?</em></strong> </li>\n",
    "</ul>\n",
    "<p>Below some first step, for you to continue and expand, or there might be other things you like to check.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# you can check specific raws and columns in your data\n",
    "df.iloc[ 1:5 , 1:5 ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>You can look as some descriptive statistics, for the features (the genes) or for the cases (the single cells). Below is the example of the cells. I show mean expression, standard deviation, and other statistics for the expression of the genes in each cell. You can also look at the expression of each gene across cells.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df.describe()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>You can plot the values for some features or for some cases</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cnames = list(df.columns)\n",
    "cnames[1]\n",
    "sns.boxplot(x=df[cnames[1]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Violin plots can be usefull. They are similar to a box plot, with the addition of a rotated kernel density plot on each side. So you can see the probability density of the data at different values. \n",
    "sns.violinplot(x=df[cnames[1]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>You can plot the distrubtion of the data for each sample, or viceversa. Below I'm plotting the violin plots of the features' values (the gene expression) for the first 50 samples (our single cells). Each violin plot corresponds to a single cell.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_small = df.iloc[:, :50]\n",
    "np.shape(df_small)\n",
    "plt.figure(figsize=(16,4))\n",
    "plot=sns.violinplot(data=df_small,palette=\"Set3\",cut=0)\n",
    "plt.setp(plot.get_xticklabels(), rotation=90)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's look for <strong><em>outliers</em></strong>. A standard appraoch with outliers is to compute the inter quantile range, and use this to define outliers and filter them as below.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's try to eliminate outliers using the quantile range.</p>\n",
    "<p>PS. Create a new dataset. It is always tidier in EDA. You can eliminate the old one later if you are happy with your new filtered or transformed dataset.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_noOut = df[~((df < (Q1 - 1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "df_noOut.shape\n",
    "df_noOut.head(3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Let's look at our violin plots again, for the dataset with outliers removed:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.boxplot(x=df_noOut[cnames[1]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_noOut_small = df.iloc[:, :50]\n",
    "np.shape(df_noOut_small)\n",
    "plt.figure(figsize=(16,4))\n",
    "plot=sns.violinplot(data=df_noOut_small,palette=\"Set3\",cut=0)\n",
    "plt.setp(plot.get_xticklabels(), rotation=90)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>They don't look good. We have just zeros now. Simply removing outliers would not work here, as many genes/features would simply be 0 if we excluded the outliers. So we need to proceed differently, as <em>the outliers seem to be the values carrying the information in this case</em>.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>In fact you might have observed that <strong><em>the data are sparse</em></strong>.</p>\n",
    "<p>Features with sparse data are features that have mostly zero values. For example, a sensor connected with a door will send a signal only when there is a movement of the door. The seonsor recording will have mostly zero values, because the door is not always moving. The rare non-zero values will be the valuable information: somebody is entering the room. Large sparse matrices are common, and encountered often in applied machine learning tasks. Examples of sparse data include data encodings that map categories to counts, vectors of one-hot-encoded words or counts of categorical data. On the other hand, features with dense data have predominantly non-zero values.</p>\n",
    "<ul>\n",
    "<li><strong><em>can you quantify the sparsity?</em></strong></li>\n",
    "<li><strong><em>would using sparse matrix representation be an advantage?</em></strong></li>\n",
    "<li><strong><em>what would you do to adress this sparsity?</em></strong></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>You can also inspect summary statistics of the <strong><em>distribution</em></strong> of your data. For example you can look at Skewness and Kurtosis of the gene expression profiles.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from scipy.stats import kurtosis, skew\n",
    "colN = np.shape(df)[1]\n",
    "colN\n",
    "df_skew_cells = []\n",
    "for i in range(colN) :     \n",
    "     v_df = df[cnames[i]]\n",
    "     df_skew_cells += [skew(v_df)]   \n",
    "  #  df_skew_cells += [df[cnames[i]].skew()]\n",
    "df_skew_cells\n",
    "sns.histplot(df_skew_cells,bins=100)\n",
    "plt.xlabel('Skewness of single cells expression profiles - original df')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_kurt_cells = []\n",
    "for i in range(colN) :     \n",
    "     v_df = df[cnames[i]]\n",
    "     df_kurt_cells += [kurtosis(v_df)]   \n",
    " #   df_kurt_cells += [df[cnames[i]].kurt()]\n",
    "df_kurt_cells\n",
    "sns.histplot(df_kurt_cells,bins=100)\n",
    "plt.xlabel('Kurtosis of single cells expression profiles - original df')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>For reference Skewness and Kurtosis for a normal distribution are below.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "xnorm = np.random.normal(0, 2, 10000000)   # create random values based on a normal distribution\n",
    "xnorm \n",
    "\n",
    "print( \"Excess kurtosis of normal distribution: \",  kurtosis(xnorm) )\n",
    "print( \"Skewness of normal distribution: \", skew(xnorm) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>The distribution are highly non-normal, skewed with heavy tails. Why is this a problem?</p>\n",
    "<p><strong><em>Data transformation</em></strong> can be an option. For example, you can try to log the data. Log based 2 is often used as +1 indicate doubling of the feature abundance (gene expression in this case) and -1 halving of the feature abundance/gene expression. In this way, changes in the values of the feature upwards or downwards are symmetrical, so up-regulation and down-regulation of a gene with respect to a control is symmetrical.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df11_log2 = np.log2(df[cnames[1]]+1)\n",
    "sns.boxplot(x=df11_log2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sns.violinplot(x=df11_log2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We can check the summary statistics again, and plot the trasformed gene expression profile of each cell</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "display(df11_log2.describe().round(2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df1 = df + 1\n",
    "df1_log2 = df1.apply(np.log2)\n",
    "# I'm selecting part of the data as the plots would otherwise take too long to generate\n",
    "df1_log2_small = df1_log2.iloc[:, :50]\n",
    "np.shape(df1_log2_small)\n",
    "plt.figure(figsize=(16,4))\n",
    "plot=sns.violinplot(data=df1_log2_small,palette=\"Set3\",cut=0)\n",
    "plt.setp(plot.get_xticklabels(), rotation=90)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df1_log2_skew_cells = []\n",
    "for i in range(colN) :     \n",
    "     v_df = df1_log2[cnames[i]]\n",
    "     df1_log2_skew_cells += [skew(v_df)]   \n",
    "df1_log2_skew_cells\n",
    "sns.histplot(df1_log2_skew_cells,bins=100)\n",
    "plt.xlabel('Skewness of single cells expression profiles - log2 df')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df1_log2_kurt_cells = []\n",
    "for i in range(colN) :     \n",
    "     v_df = df1_log2[cnames[i]]\n",
    "     df1_log2_kurt_cells += [kurtosis(v_df)] \n",
    " f1_log2_kurt_cells\n",
    "sns.histplot(df1_log2_kurt_cells,bins=100)\n",
    "plt.xlabel('Kurtosis of single cells expression profiles - log2 df')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>If we are happy with this transformation we can use this transformed data in what follows.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = df1_log2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Each single cell was sequenced independently, so there might be need of normalizing the data between cells. Let's plot the gene expression distributions for each cell, and compare them.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_small = df.iloc[:, 10:30]  #just selecting part of the samples so run time not too long\n",
    "sns.displot(data=df_small,palette=\"Set3\",kind=\"kde\", bw_adjust=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>By looking at these plots, do you think the data are <strong><em>normalized</em></strong>? How would you normalize them?</p>\n",
    "<p>Try the plots above both with the \"...unfiltered...txt\" (not filtered and not normalized), \"...filtered...txt\" (filtered but not normalized)\", and with the \"..normalized...txt\" data.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>It can also be useful to check for <strong><em>duplicate raws</em></strong>. These can often happen in any data recording tasks. In our case, there could be some features that have the same counts across experiments but different names. There could be many reasons why this happens. They could be the same entity as there is redundacy in gene annotation, or they could reflect other issues, for example when in the same region there are overlapping gene annotations. It is useful to inspect and maybe drop one of the duplicate features. However, this needs to be noted and recorded, as it could create issues with data interpretation later on. For example, in our case, if two genes have the same counts we could drop one, as they are likely to be two different annotations of the same gene (or genes with overlapping genomic regions for which we cannot resolve differences in expression). If we consider both of the duplicate features/genes, we are potentially duplicating data, creating a bias. However, if we drop one of them we will miss it in further analyses. For example, the gene that has been dropped could be the one corresponding to the most recurring annotation in previous studies. If we dropped this feature without recording this in a log file, we would miss an important biological link between the current study and historical studies.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "duplicate_rows_df = df[df.duplicated(keep=False)]\n",
    "print(\"number of duplicate rows: \", duplicate_rows_df.shape)\n",
    "print(\"number of duplicate rows: \", duplicate_rows_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We could check case by case whether to remove. First let's understand where the duplicates really are.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#print(\"names of duplicate rows: \",duplicate_rows_df.index)\n",
    "duplicate_rows_df_t = duplicate_rows_df.T\n",
    "duplicate_rows_df_t\n",
    "c_dupl = duplicate_rows_df_t.corr()\n",
    "c_dupl\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# warning: the scatter plots below might take a long time if the number of duplicate features is large\n",
    "# sns.pairplot(duplicate_rows_df_t)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We can look at the statistics of the gene expression profiles of genes/features that seem duplicates. They might be features with many zeros, or many missing data.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "duplicate_rows_df_t.describe()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#df.count()      # Used to count the number of rows and columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Below we drop duplicates</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_noDup = df.drop_duplicates()\n",
    "#df_noDup\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_noDup.count()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>If we are happy that we are not missing key features by excluding duplicates we can replace our matrix/dataframe with the new reduced matrix/dataframe</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = df_noDup\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>After the basic EDA, we can explore the <strong><em>data structure</em></strong>.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We can check the correlation between features (i.e. the expression of different genes), or between samples (i.e. the correlation between gene expression profiles of the different cells), and visualize the results in tables or plots, e.g. using Heatmaps.</p>\n",
    "<p>Below I look at the correlation between samples:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "#df_small = df.iloc[:, :50]\n",
    "#c= df_small.corr()\n",
    "c= df.corr()\n",
    "midpoint = (c.values.max() - c.values.min()) /2 + c.values.min()\n",
    "#sns.heatmap(c,cmap='coolwarm',annot=True, center=midpoint )\n",
    "sns.heatmap(c,cmap='coolwarm', center=0 )\n",
    "print(\"Number of cells included: \", np.shape(c))\n",
    "print(\"Average correlation of expression profiles between cells: \", midpoint)\n",
    "print(\"Min. correlation of expression profiles between cells: \", c.values.min())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# You can also visualized using plots\n",
    "# sns.pairplot(df_small)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>You could look at the distribution of the correlation between gene expression profiles using Histogram</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.shape(c)\n",
    "type(c)\n",
    "c.head(3)\n",
    "c_small=c.iloc[:,:3]\n",
    "sns.histplot(c_small,bins=100)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Correlation between cells expression profiles')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>We expect the correlation between the gene expression profiles of the the single cells to be fairly high.</p>\n",
    "<p>Some genes will be characteristic of some cells. For example in our case we expect some genes to be expressed at high levels only in cells cultured in conditions of low oxygen (hypoxia), or viceversa. However, most of the low and/or high expressed genes will tend to be generally similar. Several genes will have a high expression across cells as they are house keeping genes needed for the basic functioning of the cell. Some genes will have low expression across cells as they are less or not essential for the normal functioning, so they will have low or no expression across cells and will only be expressed in specific circumstances.</p>\n",
    "<p>Are there some cells which are not correlated with the others? Can you explore the distributions of gene expression for these cells and check why? Do they have more zero values than other cells? Or do they have higher values?</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Next you could explore the features/genes. Are they correlated? Is this expected? Could this generate issues in the ML?</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p>Repeat the steps above for all datasets, and discuss the findings.</p>\n",
    "<p>From now on we will proceed with the <strong>pre-processed, filtered and normalized, data</strong>. We will use the data file with name \"....3000...\". These are not only data which have been filtered and processed to address the issues discussed in the EDA, but I have also selected the 3000 <strong>most variable</strong> features. This is a first arbitrary threshold to focus on the most informative features for the purpose of this analysis. However, there are many other methods to reduce dimensionality. Can you suggest and discuss other approaches?</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr/>\n",
    "<hr/>\n",
    "<h3 id=\"Unsupervised-Learning\">Unsupervised Learning<a class=\"anchor-link\" href=\"#Unsupervised-Learning\">¶</a></h3><p>Please use the \"...Train.txt\" dataset. I have kept some data on the side for you to test you results at the end.</p>\n",
    "<p>I know you have been introduced to PCA and clustering libraries, so please use them as you wish to explore these data further.</p>\n",
    "<p>What can these methods tell us? Please discuss the results and justify your choices.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<hr/>\n",
    "<hr/>\n",
    "<h3 id=\"Supervised-Learning\">Supervised Learning<a class=\"anchor-link\" href=\"#Supervised-Learning\">¶</a></h3><p>We have discussed in class that the way a cell responds to low oxygen conditions (hypoxia) is a relevant phenotype for several diseases, and in particular for cancer. Hypoxia is one of the key physiological differences between cancer and normal tissues. Exposure to hypoxia selects for cancer cells with an aggressive phenotypes. Cells under hypoxia are resistant to many different treatments, and they are likely to metastatize to distant sites. Our general aim is to learn a classifier which allow us to predict if a cell is being exposed to low oxygen (hypoxia).</p>\n",
    "<p>The possible steps you might want to carry out are:</p>\n",
    "<ul>\n",
    "<li>The first task could be to develop a classifier in each cell type using one or more ML appraoches.</li>\n",
    "<li>You could start from the data or from the reduced data. Please justify your choices.</li>\n",
    "<li>Could you apply some feature selection? How will you apply it? </li>\n",
    "<li>You could compare the performance of the different classifiers learnt with different methods, and discuss your findings.</li>\n",
    "<li>You coud compare the classifiers between cell types. Is the performance similar?</li>\n",
    "<li>Are the features retained by the classifiers in common between cell types? </li>\n",
    "<li>You could test the classifier as predictor in a cell type where it was not developed. Does it predict well? </li>\n",
    "<li>Could you develop a general classifier, independent of cell type?</li>\n",
    "<li>You could test the predictivity of the classifier when you use it in data gathered with different technologies. How does it perform? Why? Are some ML methods better at this? Could you develop a technique </li>\n",
    "</ul>\n",
    "<p>Present and discuss your results.</p>\n",
    "<p>The ultimate task will be to predict the correct labels (hypoxia or normoxia) in the test set. You will be given the test set as last step, and you will need to include the predicted labels in a separate file, in the form of a table/tab delimited file, which I will check against the real labels after you have handed in your reports.</p>\n",
    "<p>Send the reports to me and I will share with the rest of the course instructors for evaluation.</p>\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
